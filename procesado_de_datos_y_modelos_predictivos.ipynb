{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\programdata\\anaconda3\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.45.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.24.7)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.20.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading grpcio-1.66.2-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading optree-0.13.0-cp311-cp311-win_amd64.whl.metadata (48 kB)\n",
      "     ---------------------------------------- 0.0/48.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 48.7/48.7 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl (385.0 MB)\n",
      "   ---------------------------------------- 0.0/385.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/385.0 MB 16.2 MB/s eta 0:00:24\n",
      "   ---------------------------------------- 1.2/385.0 MB 18.4 MB/s eta 0:00:21\n",
      "   ---------------------------------------- 2.5/385.0 MB 19.9 MB/s eta 0:00:20\n",
      "   ---------------------------------------- 4.2/385.0 MB 24.3 MB/s eta 0:00:16\n",
      "    --------------------------------------- 5.6/385.0 MB 27.7 MB/s eta 0:00:14\n",
      "    --------------------------------------- 7.8/385.0 MB 31.2 MB/s eta 0:00:13\n",
      "    --------------------------------------- 9.5/385.0 MB 32.1 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 11.9/385.0 MB 40.9 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 15.1/385.0 MB 50.4 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 18.2/385.0 MB 59.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 21.5/385.0 MB 65.6 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 23.8/385.0 MB 59.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 26.7/385.0 MB 65.2 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 29.0/385.0 MB 59.8 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 31.0/385.0 MB 59.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 34.3/385.0 MB 65.2 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 36.4/385.0 MB 65.6 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 39.6/385.0 MB 72.6 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 42.7/385.0 MB 65.2 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 45.3/385.0 MB 65.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 48.3/385.0 MB 65.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 51.7/385.0 MB 65.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 55.3/385.0 MB 65.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 57.5/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 60.5/385.0 MB 73.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 63.0/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 66.5/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 69.9/385.0 MB 72.6 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 72.4/385.0 MB 65.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 75.3/385.0 MB 65.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 78.3/385.0 MB 72.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 80.9/385.0 MB 65.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 83.9/385.0 MB 65.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 86.5/385.0 MB 72.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 89.8/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 92.4/385.0 MB 72.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 95.8/385.0 MB 65.6 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 99.1/385.0 MB 73.1 MB/s eta 0:00:04\n",
      "   ---------- ---------------------------- 101.3/385.0 MB 72.6 MB/s eta 0:00:04\n",
      "   ---------- ---------------------------- 103.1/385.0 MB 59.8 MB/s eta 0:00:05\n",
      "   ---------- ---------------------------- 103.4/385.0 MB 54.4 MB/s eta 0:00:06\n",
      "   ---------- ---------------------------- 105.8/385.0 MB 43.7 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 109.2/385.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 112.8/385.0 MB 50.4 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 116.0/385.0 MB 72.6 MB/s eta 0:00:04\n",
      "   ----------- --------------------------- 118.4/385.0 MB 72.6 MB/s eta 0:00:04\n",
      "   ------------ -------------------------- 121.6/385.0 MB 65.2 MB/s eta 0:00:05\n",
      "   ------------ -------------------------- 125.4/385.0 MB 65.6 MB/s eta 0:00:04\n",
      "   ------------- ------------------------- 128.7/385.0 MB 73.1 MB/s eta 0:00:04\n",
      "   ------------- ------------------------- 132.6/385.0 MB 73.1 MB/s eta 0:00:04\n",
      "   ------------- ------------------------- 135.8/385.0 MB 72.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------ 138.9/385.0 MB 72.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------ 141.1/385.0 MB 73.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------ 145.1/385.0 MB 65.2 MB/s eta 0:00:04\n",
      "   --------------- ----------------------- 148.8/385.0 MB 72.6 MB/s eta 0:00:04\n",
      "   --------------- ----------------------- 152.0/385.0 MB 73.1 MB/s eta 0:00:04\n",
      "   --------------- ----------------------- 153.8/385.0 MB 65.6 MB/s eta 0:00:04\n",
      "   --------------- ----------------------- 157.3/385.0 MB 65.6 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 160.8/385.0 MB 65.6 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 162.0/385.0 MB 59.5 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 164.2/385.0 MB 59.5 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 165.6/385.0 MB 59.5 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 168.8/385.0 MB 54.7 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 172.1/385.0 MB 54.7 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 175.2/385.0 MB 65.6 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 177.9/385.0 MB 73.1 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 181.1/385.0 MB 73.1 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 184.2/385.0 MB 59.5 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 187.0/385.0 MB 65.6 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 190.8/385.0 MB 72.6 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 193.4/385.0 MB 81.8 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 195.9/385.0 MB 72.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 200.2/385.0 MB 65.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 203.5/385.0 MB 73.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 206.7/385.0 MB 81.8 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 210.0/385.0 MB 65.2 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 213.4/385.0 MB 65.2 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 215.8/385.0 MB 59.8 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 218.8/385.0 MB 72.6 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 221.9/385.0 MB 65.2 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 225.4/385.0 MB 65.6 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 227.6/385.0 MB 65.6 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 231.6/385.0 MB 65.6 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 235.1/385.0 MB 65.2 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 236.4/385.0 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 239.8/385.0 MB 59.8 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 242.6/385.0 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 246.2/385.0 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 248.4/385.0 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 251.9/385.0 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 255.2/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 258.6/385.0 MB 72.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 261.7/385.0 MB 65.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 263.9/385.0 MB 72.6 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 266.7/385.0 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 269.4/385.0 MB 65.2 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 272.9/385.0 MB 73.1 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 276.4/385.0 MB 73.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 279.7/385.0 MB 73.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 282.3/385.0 MB 72.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 284.5/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 287.9/385.0 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 290.0/385.0 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 293.2/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 296.7/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 298.8/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 301.3/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 304.6/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 307.0/385.0 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 310.1/385.0 MB 65.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 313.7/385.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 315.8/385.0 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 319.1/385.0 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 322.1/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 325.5/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 328.2/385.0 MB 73.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 331.2/385.0 MB 65.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 334.4/385.0 MB 65.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 337.7/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 340.9/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 342.2/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 346.2/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 349.5/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 353.1/385.0 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 356.3/385.0 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 360.3/385.0 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 363.4/385.0 MB 73.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 365.5/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 369.0/385.0 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 371.6/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 374.5/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.3/385.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  380.9/385.0 MB 72.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  383.9/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.0/385.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 385.0/385.0 MB 12.8 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n",
      "Downloading grpcio-1.66.2-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 3.5/4.3 MB 74.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 54.9 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------  3.0/3.0 MB 96.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 63.7 MB/s eta 0:00:00\n",
      "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 36.6 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.5/26.4 MB 77.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 6.4/26.4 MB 80.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 9.6/26.4 MB 76.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 13.1/26.4 MB 73.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 16.3/26.4 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.8/26.4 MB 73.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.4/26.4 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.9/26.4 MB 73.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 38.4 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl (126 kB)\n",
      "   ---------------------------------------- 0.0/126.7 kB ? eta -:--:--\n",
      "   -------------------------------------- - 122.9/126.7 kB ? eta -:--:--\n",
      "   -------------------------------------- - 122.9/126.7 kB ? eta -:--:--\n",
      "   -------------------------------------- - 122.9/126.7 kB ? eta -:--:--\n",
      "   -------------------------------------- 126.7/126.7 kB 931.9 kB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 3.6/5.5 MB 77.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 58.4 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 31.4 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp311-cp311-win_amd64.whl (283 kB)\n",
      "   ---------------------------------------- 0.0/283.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 283.7/283.7 kB 17.1 MB/s eta 0:00:00\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.9.0\n",
      "    Uninstalling h5py-3.9.0:\n",
      "      Successfully uninstalled h5py-3.9.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.2 h5py-3.12.1 keras-3.5.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.0 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "import unicodedata\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.metrics import edit_distance\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/datasetia_full_1.csv', index_col = 0)\n",
    "df2 = pd.read_csv('data/datasetia_full_2.csv', index_col = 0)\n",
    "df3 = pd.read_csv('data/datasetia_full_3.csv', index_col = 0)\n",
    "df4 = pd.read_csv('data/datasetia_full_3_4.csv', index_col = 0)\n",
    "df5 = pd.read_csv('data/datasetia_full_5.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos los dos archivos\n",
    "df = pd.concat([df1, df2, df3, df4, df5], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_1: 2556\n",
      "df_2: 2556\n",
      "df_3: 2557\n",
      "df_4: 5090\n",
      "df_5: 2535\n",
      "-----------\n",
      "df: 15294\n"
     ]
    }
   ],
   "source": [
    "print(f'df_1: {len(df1)}')\n",
    "print(f'df_2: {len(df2)}')\n",
    "print(f'df_3: {len(df3)}')\n",
    "print(f'df_4: {len(df4)}')\n",
    "print(f'df_5: {len(df5)}')\n",
    "print('-----------')\n",
    "print(f'df: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE 1: HERRAMIENTA DE AYUDA EN LA SIMILITUD DE MARCAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, hacemos una primera visualización de los datos para ver que estructura tiene nuestro *dataframe*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero_expediente</th>\n",
       "      <th>resolucion</th>\n",
       "      <th>numero_de_resolución</th>\n",
       "      <th>denominacion</th>\n",
       "      <th>vigencia</th>\n",
       "      <th>titular</th>\n",
       "      <th>clase</th>\n",
       "      <th>gaceta</th>\n",
       "      <th>tipo</th>\n",
       "      <th>fecha_solicitud</th>\n",
       "      <th>fecha_resolucion</th>\n",
       "      <th>nombre_opositor</th>\n",
       "      <th>signo_opositor_opositores</th>\n",
       "      <th>argumento_oposición</th>\n",
       "      <th>explicacion_argumentos_oposicion</th>\n",
       "      <th>resolucion_organismo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>SD2021/0080419</td>\n",
       "      <td>aprobada_sin_oposicion</td>\n",
       "      <td>17413</td>\n",
       "      <td>Enzoimmune Active Immune Modulator</td>\n",
       "      <td>08.06.2031</td>\n",
       "      <td>Rosetta Lifecare Bulgaria</td>\n",
       "      <td>5</td>\n",
       "      <td>939</td>\n",
       "      <td>Mixta</td>\n",
       "      <td>26 de agosto de 2021</td>\n",
       "      <td>31 de marzo de 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conceder el registro de la Marca  Enzoimmune A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8241</th>\n",
       "      <td>SD2022/0001149</td>\n",
       "      <td>aprobada_sin_oposicion</td>\n",
       "      <td>56790</td>\n",
       "      <td>VOLVIDIS</td>\n",
       "      <td>16.11.2031</td>\n",
       "      <td>SYNGENTA CROP PROTECTION AG</td>\n",
       "      <td>5</td>\n",
       "      <td>960.0</td>\n",
       "      <td>Nominativa</td>\n",
       "      <td>6 de enero de 2022</td>\n",
       "      <td>24 de agosto de 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conceder el registro de la Marca  VOLVIDIS (No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>SD2018/0067789</td>\n",
       "      <td>aprobada_sin_oposicion</td>\n",
       "      <td>706</td>\n",
       "      <td>PLINAZOLIN</td>\n",
       "      <td>30 de mayo de 2028</td>\n",
       "      <td>Syngenta Participations AG</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nominativa</td>\n",
       "      <td>29/05/2018</td>\n",
       "      <td>26 de febrero de 2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conceder el registro de la Marca PLINAZOLIN (N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15001</th>\n",
       "      <td>SD2022/0099844</td>\n",
       "      <td>negada_sin_oposicion</td>\n",
       "      <td>6278</td>\n",
       "      <td>PDPAOLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SASMAT RETAIL S.L.</td>\n",
       "      <td>14</td>\n",
       "      <td>980.0</td>\n",
       "      <td>Nominativa</td>\n",
       "      <td>29 de septiembre de 2022</td>\n",
       "      <td>29 de febrero de 2024</td>\n",
       "      <td>PAOLACALZADOS PABLO, S.L.</td>\n",
       "      <td>PAOLA</td>\n",
       "      <td>Artículo 136 literal a) de la Decisión 486 de ...</td>\n",
       "      <td>El signo solicitado (PDPAOLA) es similar a la ...</td>\n",
       "      <td>Negar el registro de la Marca PDPAOLA (Nominat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>SD2018/0058851</td>\n",
       "      <td>aprobada_sin_oposicion</td>\n",
       "      <td>27993</td>\n",
       "      <td>CTL (Nominativa)</td>\n",
       "      <td>30.04.2028</td>\n",
       "      <td>Crisis Text Line, Inc.</td>\n",
       "      <td>[38, 45]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nominativa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15 de julio de 2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conceder el registro de la Marca CTL (Nominati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      numero_expediente              resolucion  numero_de_resolución                        denominacion            vigencia                      titular     clase gaceta        tipo           fecha_solicitud       fecha_resolucion            nombre_opositor signo_opositor_opositores                                argumento_oposición                   explicacion_argumentos_oposicion                               resolucion_organismo\n",
       "5010     SD2021/0080419  aprobada_sin_oposicion                 17413  Enzoimmune Active Immune Modulator          08.06.2031    Rosetta Lifecare Bulgaria         5    939       Mixta      26 de agosto de 2021    31 de marzo de 2022                        NaN                       NaN                                                NaN                                                NaN  Conceder el registro de la Marca  Enzoimmune A...\n",
       "8241     SD2022/0001149  aprobada_sin_oposicion                 56790                            VOLVIDIS          16.11.2031  SYNGENTA CROP PROTECTION AG         5  960.0  Nominativa        6 de enero de 2022   24 de agosto de 2022                        NaN                       NaN                                                NaN                                                NaN  Conceder el registro de la Marca  VOLVIDIS (No...\n",
       "3397     SD2018/0067789  aprobada_sin_oposicion                   706                          PLINAZOLIN  30 de mayo de 2028   Syngenta Participations AG         5    NaN  Nominativa                29/05/2018  26 de febrero de 2019                        NaN                       NaN                                                NaN                                                NaN  Conceder el registro de la Marca PLINAZOLIN (N...\n",
       "15001    SD2022/0099844    negada_sin_oposicion                  6278                             PDPAOLA                 NaN           SASMAT RETAIL S.L.        14  980.0  Nominativa  29 de septiembre de 2022  29 de febrero de 2024  PAOLACALZADOS PABLO, S.L.                     PAOLA  Artículo 136 literal a) de la Decisión 486 de ...  El signo solicitado (PDPAOLA) es similar a la ...  Negar el registro de la Marca PDPAOLA (Nominat...\n",
       "3208     SD2018/0058851  aprobada_sin_oposicion                 27993                    CTL (Nominativa)          30.04.2028       Crisis Text Line, Inc.  [38, 45]    NaN  Nominativa                       NaN    15 de julio de 2019                        NaN                       NaN                                                NaN                                                NaN  Conceder el registro de la Marca CTL (Nominati..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas que nos van a interesar para el desarrollo del modelo contienen la siguiente información:\n",
    "\n",
    "- **numero_expediente**: identificador de la solicitud por parte de una empresa para registrar una marca\n",
    "- **resolucion**: resultado de la solicitud.\n",
    "- **denominacion**: nombre de la marca que se quiere registrar\n",
    "- **titular**: nombre de la empresa que quiere registrar la marca\n",
    "- **clase**: categoría de la marca que se quiere registrar\n",
    "- **tipo**: tipo de registro que se quiere hacer (nombre, imágen o las dos)\n",
    "- **signo_opositor_opositores**: marca que hace oposición a la que se intenta registrar\n",
    "- **nombre_opositor**: empresa dueña de la marca que hace oposicion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el tipo de dato que presenta cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15294 entries, 0 to 15293\n",
      "Data columns (total 16 columns):\n",
      " #   Column                            Non-Null Count  Dtype \n",
      "---  ------                            --------------  ----- \n",
      " 0   numero_expediente                 15294 non-null  object\n",
      " 1   resolucion                        15294 non-null  object\n",
      " 2   numero_de_resolución              15294 non-null  int64 \n",
      " 3   denominacion                      14623 non-null  object\n",
      " 4   vigencia                          10585 non-null  object\n",
      " 5   titular                           15293 non-null  object\n",
      " 6   clase                             15293 non-null  object\n",
      " 7   gaceta                            11569 non-null  object\n",
      " 8   tipo                              15293 non-null  object\n",
      " 9   fecha_solicitud                   13097 non-null  object\n",
      " 10  fecha_resolucion                  15287 non-null  object\n",
      " 11  nombre_opositor                   2934 non-null   object\n",
      " 12  signo_opositor_opositores         5151 non-null   object\n",
      " 13  argumento_oposición               5229 non-null   object\n",
      " 14  explicacion_argumentos_oposicion  5228 non-null   object\n",
      " 15  resolucion_organismo              15269 non-null  object\n",
      "dtypes: int64(1), object(15)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la primera visualización de los datos, podemos ver como hay 3 columnas: *vigencia*, *fecha_solicitud* y *fecha_resolucion* que, haciendo referencia a fechas, son de tipo *object* y, además, presentan formatos diferentes entre sí. Vamos a transformar las columnas a tipo *datetime* y homogeneizar el formato entre ellas.\n",
    "\n",
    "El formato más conflictivo vendrá de los campos de tipo '02 de junio de 2023', '02 junio de 2023' o '2 jun. 2023', ya que pandas no reconoce el nombre del mes en español. Para ello, creamos un diccionario donde convirtamos el mes de una palabra a un número. Posteriormente, con el uso de expresiones regulares, buscamos los resgistros con ese formato y lo modificamos al formato *año-mes-dia*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para los nombres de los meses en español\n",
    "meses_espanol = {\n",
    "    'enero': '01', 'febrero': '02', 'marzo': '03', 'abril': '04', 'mayo': '05', 'junio': '06', \n",
    "    'julio': '07', 'agosto': '08', 'septiembre': '09', 'octubre': '10', 'noviembre': '11', 'diciembre': '12',\n",
    "    'ene.': '01', 'feb.': '02', 'mar.': '03', 'abr.': '04', 'may.': '05', 'jun.': '06', \n",
    "    'jul.': '07', 'ago.': '08', 'sep.': '09', 'oct.': '10', 'nov.': '11', 'dic.': '12',\n",
    "    'ene': '01', 'feb': '02', 'mar': '03', 'abr': '04', 'may': '05', 'jun': '06',\n",
    "    'jul': '07', 'ago': '08', 'sep': '09', 'oct': '10', 'nov': '11', 'dic': '12',\n",
    "}\n",
    "\n",
    "# Expresiones regulares para formatear los registros de tipo '02 de junio de 2023'\n",
    "def procesar_fecha_espanol(texto):\n",
    "    # Primero pasamos todo a minúscula y eliminamos espacios \n",
    "    texto = texto.lower().strip()\n",
    "\n",
    "    # A veces el ultimo caracter e sun punto, si es asi lo eliminamos\n",
    "    if texto[len(texto)-1] == '.':\n",
    "        texto = texto[:-1]\n",
    "\n",
    "    # Otras veces hay un punto en algun lugar del campo. Los ustituimos por un espacio en blanco\n",
    "    for w in texto:\n",
    "        if w=='.' or w=='º':\n",
    "            texto = texto.replace(w, ' ')\n",
    "\n",
    "    \n",
    "    # Buscar fechas en formato 'dd de mes de yyyy' o 'd de mes de yyyy'\n",
    "    match = re.search(r'(\\d{1,2})\\s+(?:de\\s+)?([enero|febrero|marzo|abril|mayo|junio|julio|sgosto|septiembre|octubre|noviembre|diciembre]|[a-zA-Záéíóúñ]{3,}\\.?\\s*|[a-zA-Záéíóúñ]+)\\s+(?:del\\s+|de\\s+)?(\\d{4})', texto) \n",
    "    # \\d representa cualquier digito del 1 al 9. \n",
    "    # {1,2} representa uno o dos digitos. \n",
    "    # \\s representa espacio en blanco. \n",
    "    # ? representa que es un bloque opcional\n",
    "    # con el uso de () en la expresion regular anterior podemos definir grupos. En este caso usaremos el grupo dia, mes y año para representar estos valores\n",
    "    if match:\n",
    "        dia = match.group(1).strip()\n",
    "        mes = match.group(2).strip()\n",
    "        año = match.group(3).strip()\n",
    "        if 'de' in dia or 'de' in mes or 'de' in año:\n",
    "            match2 = re.search(r'(enero|febrero|marzo|abril|mayo|junio|julio|agosto|septiembre|octubre|noviembre|diciembre)\\s+(\\d{1,2})\\s+de\\s+(\\d{4})', texto)\n",
    "            if match2:\n",
    "                dia = match2.group(2).strip()\n",
    "                mes = match2.group(1).strip()\n",
    "                año = match2.group(3).strip()\n",
    "        if mes in meses_espanol: # convertimos de palabra a número\n",
    "            mes_num = meses_espanol[mes]\n",
    "            # Formatear la fecha en formato numérico estándar\n",
    "            return f'{año}-{mes_num}-{int(dia):02d}'\n",
    "    \n",
    "    # Si no se encuentra el formato esperado, devuelve el texto sin cambios\n",
    "    return texto\n",
    "\n",
    "# Función para intentar convertir la fecha a un formato estándar \n",
    "def parse_date(date):\n",
    "    # Si el valor es NaN no hace nada\n",
    "    if pd.isna(date):\n",
    "        return date\n",
    "    \n",
    "    # Procesar primero las fechas con meses en español\n",
    "    date_procesada = procesar_fecha_espanol(date)\n",
    "    \n",
    "    # Intentamos convertir cualquier formato restante a formato fecha\n",
    "    try:\n",
    "        return pd.to_datetime(date_procesada, dayfirst=True, errors='coerce')\n",
    "    except Exception as e:\n",
    "        return pd.NaT\n",
    "\n",
    "# Aplicamos la funcion a las columnas que nos interesan\n",
    "df['vigencia_formated'] = df['vigencia'].apply(parse_date)\n",
    "df['fecha_solicitud_formated'] = df['fecha_solicitud'].apply(parse_date)\n",
    "df['fecha_resolucion_formated'] = df['fecha_resolucion'].apply(parse_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que se ha realizado correctamente. Para cada una de las columnas modificadas vamos a comparar los valores nulos de la nueva columna (terminada en *_formated*) con los valores anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vigencia\n",
       "No aplica                     320\n",
       "No concedida                   47\n",
       "Denegada                       37\n",
       "No aplica, registro negado     31\n",
       ".                              14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todo OK ya que nos que son null son por no ser fecha\n",
    "df_vi = df[df['vigencia_formated'].isna() & ~df['vigencia'].isna()][['vigencia', 'vigencia_formated']]\n",
    "df_vi['vigencia'].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso vemos que los valores que no se han capturado es, o por error en los formatos (como por ejemplo *29 de junino de 2027*), o por no presentar un patrón similar a la expresión regular (como por ejemplo *diez años desde la fecha del documento*). Para el modelo que se presenta en este *notebook* no se van a utilizar las fechas, de modo que no se va a depurar. Más adelante, para futuras implementaciones, se modificará oportunamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fecha_solicitud\n",
       "No encontrado                  6\n",
       "No se encuentra en el texto    5\n",
       "No se especifica               2\n",
       "No encontrado en el texto      1\n",
       "No disponible en el texto      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fs = df[df['fecha_solicitud_formated'].isna() & ~df['fecha_solicitud'].isna()][['fecha_solicitud', 'fecha_solicitud_formated']]\n",
    "df_fs['fecha_solicitud'].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_resolucion</th>\n",
       "      <th>fecha_resolucion_formated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>de de 2016</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fecha_resolucion fecha_resolucion_formated\n",
       "671       de de 2016                       NaT"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['fecha_resolucion_formated'].isna() & ~df['fecha_resolucion'].isna()][['fecha_resolucion', 'fecha_resolucion_formated']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que esta casi todo bien ya que los únicos valores de a nueva columna que son *null* son por valores que no son fecha. Por ello, eliminamos las columnas antiguas y renombramos las nuevas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['vigencia', 'fecha_solicitud', 'fecha_resolucion'], axis=1, inplace=True)\n",
    "df.rename(columns={'vigencia_formated': 'vigencia', 'fecha_solicitud_formated': 'fecha_solicitud', 'fecha_resolucion_formated': 'fecha_resolucion'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra columna que nos va a ser de gran utilidad es *clase*. Esta columna es de tipo *string* y recoge todas las clases en las que esta registrada una marca. Es necesario convertirla de *string* a lista. Primero de todo modificaremos el formato para que sea comun a todos los registros y, posteriormente, la convertiremos a formato lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero eliminamos aquellos registros que sean nulos ya que no nos van a servir para clasificar y luego modificamos los demas formatos\n",
    "df = df.dropna(subset=['clase']).reset_index(drop=True)\n",
    "\n",
    "for pos in range(0, len(df['clase']), 1):\n",
    "    elem = df['clase'].iloc[pos].strip()\n",
    "    if ~elem.startswith('[') == -1: # los que no comiencen por '[' los forzamos a que lo hagan\n",
    "        elem = '[' + elem\n",
    "    if ~elem.endswith(']') == -1: # igual para las terminaciones\n",
    "        elem = elem + ']'\n",
    "    if 'y' in elem:\n",
    "        elem = elem.replace('y', ',') # sustituimos el valor final de 'y' en algunos registros por ',' para dar el formato lista\n",
    "    if \"'\" in elem:\n",
    "        elem = elem.replace(\"'\", '') # eliminamos las comillas de string para que todo sea formato numerico\n",
    "    if '\\n' in elem:\n",
    "        elem = elem.replace('\\n', ',') # eliminamos el caracter '\\n' por una coma de separador\n",
    "\n",
    "    df['clase'].iloc[pos] = elem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalua el contenido y lo transforma a lista\n",
    "def convertir_a_lista(valor):\n",
    "    if isinstance(valor, int):  # Verifica si es un entero\n",
    "        return [valor]  # Convierte el entero a una lista\n",
    "    elif isinstance(valor, str):  # Verifica si es una cadena\n",
    "        try:\n",
    "            # Intentar convertir la cadena a una lista\n",
    "            return ast.literal_eval(valor)\n",
    "        except (ValueError, SyntaxError):\n",
    "            # Si hay un error, devolver None\n",
    "            return None\n",
    "    return valor  # Devuelve el valor original si no es ni entero ni caden\n",
    "\n",
    "# Aplicar la conversión a la columna\n",
    "df['clase'] = df['clase'].apply(convertir_a_lista)\n",
    "df = df.dropna(subset=['clase']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos que se ha hecho bien el cambio\n",
    "type(df['clase'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos observar, de la primera visualización, que para la columna *resolucion*, existen casos que se escriben con tilde y otros sin. Es decir, hay valores que son *aprobada_con_oposicion* y otros que son *aprobada_con_oposición*. Para evitar errores en el filtrado posterior, vamos a eliminar todas las tildes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para eliminar tildes\n",
    "def quitar_tildes(texto):\n",
    "    if pd.isna(texto):  # Verificar si es NaN o None\n",
    "        return texto  # Retornar el valor tal cual\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# Aplicamos la función a la columna 'resolucion'\n",
    "df['resolucion'] = df['resolucion'].apply(quitar_tildes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resolucion\n",
       "aprobada_con_oposicion     566\n",
       "aprobada_sin_oposicion    9559\n",
       "archivada                    1\n",
       "archivado                    1\n",
       "denegada_con_oposicion       1\n",
       "desistimiento                1\n",
       "negada_con_oposicion       987\n",
       "negada_sin_oposicion      4166\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['resolucion']].groupby(['resolucion']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay 3 nuevas clases: *archivada*, *desistimmiento* y *denegada_con_oposicion*. Esta última la transformaremos a *negada_con_oposicion*, mientras que las dos primeras las eliminaremos ya que no nos aportan valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde la columna Resolución no contenga 'archivada', 'archivado', 'desistimiento'\n",
    "df = df[~df['resolucion'].isin(['archivada', 'archivado', 'desistimiento'])]\n",
    "\n",
    "# Reemplazar 'denegada_con_oposicion' por 'negada_con_oposicion' en la columna Resolución\n",
    "df['resolucion'] = df['resolucion'].replace('denegada_con_oposicion', 'negada_con_oposicion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resolucion\n",
       "aprobada_con_oposicion     566\n",
       "aprobada_sin_oposicion    9559\n",
       "negada_con_oposicion       988\n",
       "negada_sin_oposicion      4166\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oOmprobamos que esta OK\n",
    "df[['resolucion']].groupby(['resolucion']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver ahora los valores nulos que hay y si tienen sentido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numero_expediente                       0\n",
       "resolucion                              0\n",
       "numero_de_resolución                    0\n",
       "denominacion                          671\n",
       "titular                                 1\n",
       "clase                                   0\n",
       "gaceta                               3720\n",
       "tipo                                    1\n",
       "nombre_opositor                     12355\n",
       "signo_opositor_opositores           10137\n",
       "argumento_oposición                 10059\n",
       "explicacion_argumentos_oposicion    10060\n",
       "resolucion_organismo                   25\n",
       "vigencia                             5214\n",
       "fecha_solicitud                      2213\n",
       "fecha_resolucion                        8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede ser que algunos valores, que hacen referencia a la oposición de registro, tengan sentido. Esto es debido a que algunas de las solicitudes son aprobadas o negadas sin oposición. Vamos a comprobar que los valores nulos para de las columnas *nombre_opositor*, *signo_opositor_opositores*, *argumento_oposición* y *explicacion_argumentos_oposicion* se correspondan con una resolución sin oposición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre_opositor: 2\n",
      "signo_opositor_opositores: 30\n",
      "argumento_oposición: 5\n",
      "explicacion_argumentos_oposicion: 5\n"
     ]
    }
   ],
   "source": [
    "lista_resolucion = ['aprobada_sin_oposicion', 'negada_sin_oposicion']\n",
    "\n",
    "print(f\"nombre_opositor: {len(df[df['nombre_opositor'].isna() & ~df['resolucion'].isin(lista_resolucion)])}\")\n",
    "print(f\"signo_opositor_opositores: {len(df[df['signo_opositor_opositores'].isna() & ~df['resolucion'].isin(lista_resolucion)])}\")\n",
    "print(f\"argumento_oposición: {len(df[df['argumento_oposición'].isna() & ~df['resolucion'].isin(lista_resolucion)])}\")\n",
    "print(f\"explicacion_argumentos_oposicion: {len(df[df['explicacion_argumentos_oposicion'].isna() & ~df['resolucion'].isin(lista_resolucion)])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el desarrollo del modelo nos vamos a centrar principalmemnte en los casos en los que se ha hecho oposición (*aprobado_con_oposicion* y *negada_con_oposicion), que son precisamente el número de casos que se ve en la celda anterior. El resto de casos que toman el valor *nan* se deben a que son casos en los que no se ha hecho oposición y, como esas celdas hacen referencia a la oposición, están como *nan*. Como mencionabamos, son muy pocos los casos en los que hay valores faltantes de modo que lo dejaremos como está y los filtraremos en la parte de modelado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el registro de nuevas marcas influyen dos factores fundamentales:\n",
    "\n",
    "- **denominacion**: Es el nombre de la marca que se intenta registrar\n",
    "- **clase**: Categoría de negocios (por ejemplo, restauración, retail, etc.)\n",
    "\n",
    "Cuando una emprese intente registrar un nuevo nombre (*denominacion*) tiene que indicar, además del nombre, la clase en la que lo desea hacer. Por ello, los parametros de entrada serán estos dos: **nombre** y **clase**. \n",
    "\n",
    "Una vez los tengamos recogidos, filtraremos el dataset por la clase indicada por el usuario (de momento una única clase, aunque en líneas futuras se abrirá el registro a un mayor número). En este punto vamos a comprobar varias cosas:\n",
    "\n",
    "1. Que la marca que se intenta registrar no lo esté ya. Si es así directamente **no se podrá registrar**.\n",
    "2. En caso de que no esté registrada buscaremos, dentro de esa misma clase, otras **marcas similares**. Esto lo haremos mediante dos métodos:\n",
    "\n",
    "    a. **Parecido semántico**: Marcas que no se escriban igual pero tengan significados similares (por ejemplo: burger king, hamburguesas queen)\n",
    "    \n",
    "    b. **Parecido de caracteres**: Marcas que se escriban similar.\n",
    "\n",
    "    Sumado a estas dos comparaciones se dirá en la medida que las palabras se parecen (terminos percentuales).\n",
    "3. Por último, para la clase indicada por el usuario, se dará un **valor máximo y medio de similitud por clase** para aquellas solicitudes aprobadas. De esta forma el usuario podrá valorar mejor la magnitud de la similitud de la marca a registrar y tendrá un mayor **contexto** sobre si quiere iniciar el proceso o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = str(input('Introduzca el nombre de la clase que desea registrar: '))\n",
    "clase = int(input('Introduzca la clase en la que desea registrar la marcas: '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PASO 1**: Filtramos el dataset por aquellos registros que contengan la clase donde quiero registrar la marca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flt = df[df['clase'].apply(lambda x: clase in x)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PASO 2**: Almaceno en una lista el nombre de todas las marcas que ya estan actualmente registradas en esa clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "marca_lst = [df_flt['denominacion'][pos] for pos in range(0, len(df_flt), 1) if (any('aprobada' in registro for registro in df_flt['resolucion']) and pd.notna(df_flt['denominacion'][pos]) and df_flt['denominacion'][pos] is not None)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PASO 3**: Buscamos la similitud semántica y de caracteres entre el nombre que queremos registrar y los que ya estan registrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Similitud Semántica**: Vamos a utilizar el modelo preentrenado *Sentence-BERT*. De esta forma generamos *embeddings* de los nombres de las empresas y calculamos la similitud del coseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Usamos embeddings ya que son las representaciones en forma vectorial del significado de una palabra. Asi podemos hacer la comparación semántica\n",
    "# Obtenemos los embeddings de las empresas en la lista que hemos obtenido anteriormente\n",
    "embeddings_sic = modelo.encode(marca_lst)\n",
    "\n",
    "# Obtenemos el embedding de la nueva empresa\n",
    "embedding_nueva_marca = modelo.encode([nombre])\n",
    "\n",
    "# Calculamos la similitud de coseno entre la nueva empresa y cada empresa de la lista\n",
    "# USamos la distancia del coseno porque mide el ángulo entre dos vectores (embeddings)\n",
    "similitudes = cosine_similarity(embedding_nueva_marca, embeddings_sic)[0] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Similitud de Caracteres**: Vamos a hacer una comparación de los caracteres que conforman una palabra. Buscamos alabras que, aunque tengan significados totalmente diferente, se escriban similar. Para ello vamos a usar la *distancia de Levenshtein*, que mide el porcentaje de similitud basado en el número de cambios necesarios para convertir una palabra en otra. Cuanto más bajo sea el número, mayor es la similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a ir guardando en un array las distancias entre la nueva marca y las que ya hay en la BBDD\n",
    "distancias_levenshtein = []\n",
    "\n",
    "for empresa in marca_lst:\n",
    "    lev_dist = edit_distance(nombre, empresa) # Calculamos la distancia levenshtein entre la nueva marca y cada una de las que hay en la BBDD\n",
    "    max_len = max(len(nombre), len(empresa)) # Obtiene la longitud de la cadena más larga entre las dos empresas. Esto es importante porque la similitud se mide en relación con la longitud de las palabras.\n",
    "    similitud = (1 - lev_dist / max_len)  # Similitud en porcentaje\n",
    "    distancias_levenshtein.append(similitud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PASO 4**: Para coger mayor perspectiva de como de grandes o pequeños son esos porcentajes vamos a dar contexto a la situación. Para ello, para las solicutdes aprobadas con oposición, daremos el valor medio y máximo de similitud con la que se han aprobado. Haremos lo mismo para las negadas con oposición para su valor mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Aprobadas con oposicion**: Para las solicitudes que han sido aprobadas con oposicion sacamos, del par *denominacion-signo_opositor_opositores* los *embeddings* y sacamos el valor promedio y el máximo. La idea, como se ha comentado antes, es tener una visión de cuál es el valor a partir del cuál se han aprobado las solicitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para el dataset ya filtrado por la clase, filtro otra vez por la resolución\n",
    "df_flt_aprob = df_flt[df_flt['resolucion']=='aprobada_con_oposicion'].reset_index()\n",
    "\n",
    "# Vamos a ir almacenando en una lista el conjunto de dupas denominación-signo_opositor_opositores\n",
    "list_sim_aprob = []\n",
    "marca_sim_aprob = [(df_flt_aprob['denominacion'][pos], [n.strip() for n in df_flt_aprob['signo_opositor_opositores'][pos].split(',')]) for pos in range(0, len(df_flt_aprob), 1) if pd.notna(df_flt_aprob['denominacion'][pos]) and pd.notna(df_flt_aprob['signo_opositor_opositores'][pos]) and df_flt_aprob['denominacion'][pos] is not None]\n",
    "\n",
    "# Calculamos la similitud semantica entre los pares\n",
    "modelo = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "sim_aprob = []\n",
    "for m1, m2 in marca_sim_aprob:\n",
    "    embeddings_m1 = modelo.encode(m1).reshape(1, -1)\n",
    "    if type(m2)==list:\n",
    "        m2_list = []\n",
    "        for m in m2:\n",
    "            m2_list.append(modelo.encode(m).reshape(1, -1))\n",
    "        for emb in m2_list:\n",
    "            sim_aprob.append((m1, m, cosine_similarity(embeddings_m1, emb)[0][0]))\n",
    "    else:\n",
    "        embeddings_m2 = modelo.encode(m2).reshape(1, -1)   \n",
    "        sim_aprob.append((m1, m2, cosine_similarity(embeddings_m1, embeddings_m2)[0][0]))\n",
    "\n",
    "# Calculamos la similitud de caracteres\n",
    "distancias_lev_aprob = []\n",
    "for m1, m2 in marca_sim_aprob:\n",
    "    if type(m2)==list:\n",
    "        for m in m2:\n",
    "            lev_dist_aprob = edit_distance(m1, m)\n",
    "            max_len_aprob = max(len(m1), len(m)) \n",
    "            similitud_aprob = (1 - lev_dist_aprob / max_len_aprob)  \n",
    "            distancias_lev_aprob.append((m1, m, similitud_aprob))\n",
    "    else:\n",
    "            distancias_lev_aprob.append((m1, m2, similitud_aprob))\n",
    "\n",
    "# Sacamos valores máximos y medios\n",
    "v_medio_aprob_sem = np.mean([value[2] for value in sim_aprob])\n",
    "v_max_aprob_sem = max([value[2] for value in sim_aprob])\n",
    "v_medio_aprob_car = np.mean([value[2] for value in distancias_lev_aprob])\n",
    "v_max_aprob_car = max([value[2] for value in distancias_lev_aprob])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Negadas con oposicion**: Para las solicitudes que han sido negadas con oposicion sacamos, del par *denominacion-signo_opositor_opositores* los *embeddings* y \n",
    "sacamos el valor promedio y el mínimo. La idea, como se ha comentado antes, es tener una visión de cuál es el valor a partir del cuál se han denegado las solicitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Para el dataset ya filtrado por la clase, filtro otra vez por la resolución\n",
    "df_flt_nega = df_flt[df_flt['resolucion']=='negada_con_oposicion'].reset_index()\n",
    "\n",
    "# Vamos a ir almacenando en una lista el conjunto de dupas denominación-signo_opositor_opositores\n",
    "list_sim_nega = []\n",
    "marca_sim_nega = [(df_flt_nega['denominacion'][pos], [n.strip() for n in df_flt_nega['signo_opositor_opositores'][pos].split(',')]) for pos in range(0, len(df_flt_nega), 1) if pd.notna(df_flt_nega['denominacion'][pos]) and pd.notna(df_flt_nega['signo_opositor_opositores'][pos]) and df_flt_nega['denominacion'][pos] is not None]\n",
    "\n",
    "# Calculamos la similitud semantica entre los pares\n",
    "modelo = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "sim_nega = []\n",
    "for m1, m2 in marca_sim_nega:\n",
    "    embeddings_m1 = modelo.encode(m1).reshape(1, -1)\n",
    "    if type(m2)==list:\n",
    "        m2_list = []\n",
    "        for m in m2:\n",
    "            m2_list.append(modelo.encode(m).reshape(1, -1))\n",
    "        for emb in m2_list:\n",
    "            sim_nega.append((m1, m, cosine_similarity(embeddings_m1, emb)[0][0]))\n",
    "    else:\n",
    "        embeddings_m2 = modelo.encode(m2).reshape(1, -1)   \n",
    "        sim_nega.append((m1, m2, cosine_similarity(embeddings_m1, embeddings_m2)[0][0]))\n",
    "\n",
    "# Calculamos la similitud de caracteres\n",
    "distancias_lev_nega = []\n",
    "for m1, m2 in marca_sim_nega:\n",
    "    if type(m2)==list:\n",
    "        for m in m2:\n",
    "            lev_dist_nega = edit_distance(m1, m)\n",
    "            max_len_nega = max(len(m1), len(m)) \n",
    "            similitud_nega = (1 - lev_dist_nega / max_len_nega)  \n",
    "            distancias_lev_nega.append((m1, m, similitud_nega))\n",
    "    else:\n",
    "            distancias_lev_nega.append((m1, m2, similitud_nega))\n",
    "\n",
    "# Sacamos valores máximos y medios\n",
    "v_medio_nega_sem = np.mean([value[2] for value in sim_nega])\n",
    "v_min_nega_sem = min([value[2] for value in sim_nega])\n",
    "v_medio_nega_car = np.mean([value[2] for value in distancias_lev_nega])\n",
    "v_min_nega_car = min([value[2] for value in distancias_lev_nega])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nombre in marca_lst:\n",
    "    mensaje_1 = f'Lamentablemente, \"{nombre}\" ya está registrado dentro de esta clase.'\n",
    "else:\n",
    "    mensaje_1 = f'Actualmente, no existe ninguna marca registrada como \"{nombre}\" dentro de esta clase.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Estas tratando de registrat la marca \"{nombre}\" dentro de la clase {clase}.\n",
    "{mensaje_1}\n",
    "\n",
    "En esta clase hay registradas {len(marca_lst)} marcas. De ellas, para la marca que intenta registrar:\n",
    "- Hay un {max(similitudes):.2%} de similitud semántica con la marca {marca_lst[np.argmax(similitudes)]} ya registrada.\n",
    "- Hay un {max(distancias_levenshtein):.2%} de similitud de caracteres con la marca {marca_lst[np.argmax(distancias_levenshtein)]} ya registrada.\n",
    "\n",
    "Para esta clase, de todas las solicitudes que se han aprobado con oposición:\n",
    "- El valor medio de similitud semántica ha sido {v_medio_aprob_sem:.2%}, mientras que el valor máximo es del {v_max_aprob_sem:.2%}\n",
    "- El valor medio de similitud de caracteres ha sido {v_medio_aprob_car:.2%}, mientras que el valor máximo es del {v_max_aprob_car:.2%}\n",
    "\n",
    "Para las solicitudes que se han negado con oposición:\n",
    "- El valor medio de similitud semántica ha sido {v_medio_nega_sem:.2%}, mientras que el valor mínimo es del {v_min_nega_sem:.2%}\n",
    "- El valor medio de similitud de caracteres ha sido {v_medio_nega_car:.2%}, mientras que el valor mínimo es del {v_min_nega_car:.2%}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estas tratando de registrat la marca \"OPERA\" dentro de la clase 9.\n",
      "Actualmente, no existe ninguna marca registrada como \"OPERA\" dentro de esta clase.\n",
      "\n",
      "En esta clase hay registradas 3825 marcas. De ellas, para la marca que intenta registrar:\n",
      "- Hay un 52.27% de similitud semántica con la marca ARIANE ya registrada.\n",
      "- Hay un 80.00% de similitud de caracteres con la marca OPERR ya registrada.\n",
      "\n",
      "Para esta clase, de todas las solicitudes que se han aprobado con oposición:\n",
      "- El valor medio de similitud semántica ha sido 38.44%, mientras que el valor máximo es del 100.00%\n",
      "- El valor medio de similitud de caracteres ha sido 31.19%, mientras que el valor máximo es del 100.00%\n",
      "\n",
      "Para las solicitudes que se han negado con oposición:\n",
      "- El valor medio de similitud semántica ha sido 43.87%, mientras que el valor mínimo es del -7.62%\n",
      "- El valor medio de similitud de caracteres ha sido 30.46%, mientras que el valor mínimo es del 0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE 2: MODELO DE PREDICCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df[['resolucion', 'denominacion', 'clase', 'nombre_opositor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resolucion</th>\n",
       "      <th>denominacion</th>\n",
       "      <th>clase</th>\n",
       "      <th>nombre_opositor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13186</th>\n",
       "      <td>negada_sin_oposicion</td>\n",
       "      <td>OCTOPUS</td>\n",
       "      <td>[9, 17]</td>\n",
       "      <td>AMERICA TOWERTECH AMERICAS LTDA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>aprobada_sin_oposicion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7984</th>\n",
       "      <td>aprobada_sin_oposicion</td>\n",
       "      <td>OPTICARE</td>\n",
       "      <td>[10, 20]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>aprobada_sin_oposicion</td>\n",
       "      <td>ACCUPOINT</td>\n",
       "      <td>[8]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>aprobada_sin_oposicion</td>\n",
       "      <td>ORIGINAL NEW YORK SELTZER  (Nominativa)</td>\n",
       "      <td>[32]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   resolucion                             denominacion     clase                   nombre_opositor\n",
       "13186    negada_sin_oposicion                                  OCTOPUS   [9, 17]  AMERICA TOWERTECH AMERICAS LTDA.\n",
       "1019   aprobada_sin_oposicion                                      NaN       [1]                               NaN\n",
       "7984   aprobada_sin_oposicion                                 OPTICARE  [10, 20]                               NaN\n",
       "5099   aprobada_sin_oposicion                                ACCUPOINT       [8]                               NaN\n",
       "581    aprobada_sin_oposicion  ORIGINAL NEW YORK SELTZER  (Nominativa)      [32]                               NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos a ver los nulos que hay en cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resolucion             0\n",
       "denominacion         671\n",
       "clase                  0\n",
       "nombre_opositor    12355\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los casos en los que oposicion sea *NaN* los eliminamos ya que no aportan valor. En el caso de *nombre_opositor* los sustituimos por 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos en denominacion\n",
    "dataset = dataset.dropna(subset=['denominacion'])\n",
    "\n",
    "# Sustituimos por 0 en nombre_opositor\n",
    "dataset['nombre_opositor'] = dataset['nombre_opositor'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resolucion         0\n",
       "denominacion       0\n",
       "clase              0\n",
       "nombre_opositor    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos que se haya hecho bien\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo rimero que tenemos que hacer es transformar la columna *target* en valores numéricos. Para ello mapeamos los valores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['resolucion'] = dataset['resolucion'].replace({'aprobada_con_oposicion': 1, 'aprobada_sin_oposicion': 1, \n",
    "                                                       'negada_con_oposicion': 0, 'negada_sin_oposicion': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las variables *denominacion* y *nombre_opositor* realizamos un *One Hot Encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_encoded = pd.get_dummies(dataset, columns=['denominacion', 'nombre_opositor'], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, como la variable clase es una lista de elementos, expandimos la lista para que cada valor este en una columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar la columna 'clase' directamente en el DataFrame original\n",
    "df_clase = dataset_encoded['clase'].apply(pd.Series)\n",
    "\n",
    "# Renombrar las columnas para que tengan un formato más descriptivo (opcional)\n",
    "df_clase.columns = [f'clase_{i+1}' for i in range(df_clase.shape[1])]\n",
    "\n",
    "# Asignar las nuevas columnas al DataFrame original\n",
    "for col in df_clase.columns:\n",
    "    dataset_encoded[col] = df_clase[col]\n",
    "\n",
    "# Eliminar la columna original 'clase'\n",
    "dataset_encoded.drop(columns=['clase'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ahora, tras haber pasado las listas a multiples columnas se habrán generado valores *Na*, los sustituimos por 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_encoded.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez teemos el dataset, dividimos entre X e y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_encoded.drop('resolucion', axis=1)\n",
    "y = dataset_encoded['resolucion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos entre *train* y *test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1903)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (10225, 13797)\n",
      "X_test: (4383, 13797)\n",
      "y_train: (10225,)\n",
      "y_test: (4383,)\n"
     ]
    }
   ],
   "source": [
    "# Vemos dimensiones\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'X_test: {X_test.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print(f'y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comprobar también si las clases están balanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resolucion\n",
       "1    6690\n",
       "0    3535\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no lo estan aplicamos *SMOTE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar PCA para reducir a 100 componentes principales\n",
    "pca = PCA(n_components=100)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# Ahora aplica SMOTE en los datos reducidos\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos los resultados tras el balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resolucion\n",
       "0    6690\n",
       "1    6690\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la parte de modelado vamos a emplear diferentes modelos y evaluar cual funciona mejor. Los modelos que se van a probar son:\n",
    "\n",
    "- **Regresión logística**\n",
    "- **Árbol de decisión**\n",
    "- **Random Forest**\n",
    "- **Red Neuronal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vamos a aplicar un *Grid Search* para afinar bien el modelo, definimos un diccionario con los parámetros en función del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        'penalty': ['l2'],  # Regresión con regularización L2\n",
    "        'C': [0.01, 0.1, 1, 10],  # Inversa de la fuerza de regularización\n",
    "        'solver': ['lbfgs'],  # Optimizador\n",
    "        'max_iter': [100, 200]  # Número de iteraciones\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        'criterion': ['gini', 'entropy'],  # Función para medir la calidad del split\n",
    "        'max_depth': [None, 10, 20],  # Profundidad máxima del árbol\n",
    "        'min_samples_split': [2, 10, 20],  # Mínimo número de muestras para un split\n",
    "        'min_samples_leaf': [1, 5, 10]  # Mínimo número de muestras por hoja\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [100, 200],  # Número de árboles en el bosque\n",
    "        'max_depth': [None, 10, 20],  # Profundidad máxima de cada árbol\n",
    "        'min_samples_split': [2, 5, 10],  # Mínimo número de muestras para un split\n",
    "        'min_samples_leaf': [1, 2],  # Mínimo número de muestras por hoja\n",
    "        'bootstrap': [True, False]  # Si usar muestreo con reemplazo\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos también otro diccionario con los modelos que vamos a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos inicializados (sin parámetros)\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lanzamos cada uno de los modelos del diccionario anterior con su *Grid Search* correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando GridSearch para Logistic Regression...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Mejores hiperparámetros para Logistic Regression: {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Realizando GridSearch para Decision Tree...\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Mejores hiperparámetros para Decision Tree: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Realizando GridSearch para Random Forest...\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Mejores hiperparámetros para Random Forest: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Para cada modelo, realizar la búsqueda de hiperparámetros con GridSearchCV\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f'Realizando GridSearch para {name}...')\n",
    "    \n",
    "    # GridSearchCV con validación cruzada (5 folds)\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=5, verbose=2, n_jobs=-1)\n",
    "    \n",
    "    # Entrenar usando el conjunto de entrenamiento\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Guardar el mejor modelo\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    \n",
    "    print(f'Mejores hiperparámetros para {name}: {grid_search.best_params_}')\n",
    "    print('\\n' + '-'*60 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos los mejores modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando Logistic Regression...\n",
      "Evaluando Decision Tree...\n",
      "Evaluando Random Forest...\n"
     ]
    }
   ],
   "source": [
    "resultados = []\n",
    "\n",
    "# Iterar sobre los modelos\n",
    "for name, best_model in best_models.items():\n",
    "    print(f'Evaluando {name}...')\n",
    "\n",
    "    # Prediccion en el conjunto de test\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Evaluar rendimiento\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Añadir los resultados a la lista\n",
    "    resultados.append({\n",
    "        'Modelo': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Matriz de Confusión': confusion,\n",
    "        'Precision': report['weighted avg']['precision'],\n",
    "        'Recall': report['weighted avg']['recall'],\n",
    "        'F1-Score': report['weighted avg']['f1-score']\n",
    "    })\n",
    "\n",
    "# Convertir la lista de resultados en un DataFrame de pandas\n",
    "df_resultados = pd.DataFrame(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Matriz de Confusión</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.767511</td>\n",
       "      <td>[[694, 843], [176, 2670]]</td>\n",
       "      <td>0.773243</td>\n",
       "      <td>0.767511</td>\n",
       "      <td>0.747491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.671002</td>\n",
       "      <td>[[1012, 525], [917, 1929]]</td>\n",
       "      <td>0.694384</td>\n",
       "      <td>0.671002</td>\n",
       "      <td>0.677440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.761807</td>\n",
       "      <td>[[726, 811], [233, 2613]]</td>\n",
       "      <td>0.761002</td>\n",
       "      <td>0.761807</td>\n",
       "      <td>0.745207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo  Accuracy         Matriz de Confusión  Precision    Recall  F1-Score\n",
       "0  Logistic Regression  0.767511   [[694, 843], [176, 2670]]   0.773243  0.767511  0.747491\n",
       "1        Decision Tree  0.671002  [[1012, 525], [917, 1929]]   0.694384  0.671002  0.677440\n",
       "2        Random Forest  0.761807   [[726, 811], [233, 2613]]   0.761002  0.761807  0.745207"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, vamos a desarrollar una red neuronal que se encargue de hacer la predicción. En este caso vamos a enfocar el problema desde otra perspectiva, simplificando y optimizando la parte de preprocesado. En los modelos anteriores hemos empleado *One Hot Encoding*, generando un gran número de columnas. En este caso vamos a plantear la estandarización de dos formas diferentes:\n",
    "\n",
    "- **denominacion** y **nombre_opositor**: vamos a utilizar embeddings para representar las cadenas de texto de forma numérica.\n",
    "- **clase**: no hace falta tocar nada ya que se pueden introducir en las redes neuronales\n",
    "- **resolucion**: lo dejamos como 1 y 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_rn = df[['resolucion', 'denominacion', 'clase', 'nombre_opositor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resolucion</th>\n",
       "      <th>denominacion</th>\n",
       "      <th>clase</th>\n",
       "      <th>nombre_opositor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3125</th>\n",
       "      <td>aprobada_sin_oposicion</td>\n",
       "      <td>STA Satellite Max</td>\n",
       "      <td>[10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>aprobada_sin_oposicion</td>\n",
       "      <td>TAJ</td>\n",
       "      <td>[34]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15005</th>\n",
       "      <td>negada_sin_oposicion</td>\n",
       "      <td>Gansulin</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15267</th>\n",
       "      <td>negada_sin_oposicion</td>\n",
       "      <td>CPR Taylor</td>\n",
       "      <td>[9]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>aprobada_sin_oposicion</td>\n",
       "      <td>LE PLIAGE</td>\n",
       "      <td>[18, 25]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   resolucion       denominacion     clase nombre_opositor\n",
       "3125   aprobada_sin_oposicion  STA Satellite Max      [10]             NaN\n",
       "2179   aprobada_sin_oposicion                TAJ      [34]             NaN\n",
       "15005    negada_sin_oposicion           Gansulin   [5, 10]             NaN\n",
       "15267    negada_sin_oposicion         CPR Taylor       [9]             NaN\n",
       "1003   aprobada_sin_oposicion          LE PLIAGE  [18, 25]             NaN"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_rn.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos los valores nulos igual que hicimoz en el caso anterior y sustituimos los 'NaN', esta vez por un valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos en denominacion\n",
    "dataset_rn = dataset_rn.dropna(subset=['denominacion'])\n",
    "\n",
    "# Sustituimos por 0 en nombre_opositor\n",
    "dataset_rn['nombre_opositor'] = dataset_rn['nombre_opositor'].fillna('Sin Opositor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resolucion         0\n",
       "denominacion       0\n",
       "clase              0\n",
       "nombre_opositor    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos que se haya hecho bien\n",
    "dataset_rn.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_rn['resolucion'] = dataset_rn['resolucion'].replace({'aprobada_con_oposicion': 1, 'aprobada_sin_oposicion': 1, \n",
    "                                                             'negada_con_oposicion': 0, 'negada_sin_oposicion': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificamos las cadenas de texto de *denominacion* y *nombre_opositor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "denomination_le = LabelEncoder()\n",
    "oppositor_le = LabelEncoder()\n",
    "\n",
    "dataset_rn['denominacion'] = denomination_le.fit_transform(dataset_rn['denominacion'])\n",
    "dataset_rn['nombre_opositor'] = oppositor_le.fit_transform(dataset_rn['nombre_opositor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la columna de clase vamos a utilizar el*MultiLabelBinzarized*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "dataset_rn_clase = mlb.fit_transform(dataset_rn['clase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, separamos la variable objetivo del resto del dataset y creamos ademas las variables predictoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset_rn['resolucion']\n",
    "\n",
    "X_denominacion = dataset_rn['denominacion']\n",
    "X_opositor = dataset_rn['nombre_opositor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_denom, X_test_denom, X_train_class, X_test_class, X_train_opo, X_test_opo, y_train, y_test = train_test_split(\n",
    "    X_denominacion, dataset_rn_clase, X_opositor, y, test_size=0.3, random_state=1903)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos ahora a definir las entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input para la denominación\n",
    "input_denom = Input(shape=(1,), name='denominacion_input')\n",
    "\n",
    "# Input para el nombre_opositor\n",
    "input_opo = Input(shape=(1,), name='opositor_input')\n",
    "\n",
    "# Input para las clases codificadas (binarias)\n",
    "input_class = Input(shape=(dataset_rn_clase.shape[1],), name='class_input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y también las capas de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings para denominación y nombre_opositor\n",
    "embedding_denom = Embedding(input_dim=len(denomination_le.classes_), output_dim=10, name='denominacion_embedding')(input_denom)\n",
    "embedding_opo = Embedding(input_dim=len(oppositor_le.classes_), output_dim=10, name='opositor_embedding')(input_opo)\n",
    "\n",
    "# Convertimos los embeddings en un vector plano\n",
    "flat_denom = Flatten()(embedding_denom)\n",
    "flat_oppo = Flatten()(embedding_opo)\n",
    "\n",
    "# Concatenamos los embeddings de denominación, opositor y las clases binarizadas\n",
    "concat = Concatenate()([flat_denom, flat_oppo, input_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos las capas densas y la de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos capas densas\n",
    "dense_1 = Dense(64, activation='relu')(concat)\n",
    "dense_2 = Dense(32, activation='relu')(dense_1)\n",
    "dense_3 = Dense(16, activation='relu')(dense_2)\n",
    "\n",
    "# Capa de salida (predicción binaria)\n",
    "output = Dense(1, activation='sigmoid')(dense_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, definimos y compilamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo completo\n",
    "model = Model(inputs=[input_denom, input_opo, input_class], outputs=output)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ denominacion_input  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ opositor_input      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ denominacion_embed… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">116,030</span> │ denominacion_inp… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ opositor_embedding  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,490</span> │ opositor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ denominacion_emb… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ opositor_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ class_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ class_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,416</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ denominacion_input  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ opositor_input      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ denominacion_embed… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │    \u001b[38;5;34m116,030\u001b[0m │ denominacion_inp… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ opositor_embedding  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │     \u001b[38;5;34m21,490\u001b[0m │ opositor_input[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ denominacion_emb… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ opositor_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ class_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ class_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,416\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,561</span> (564.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m144,561\u001b[0m (564.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,561</span> (564.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m144,561\u001b[0m (564.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resumen del modelo\n",
    "model.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, entrenamos el modelo utilizando los datos de entrenamiento. Para las entradas, debemos proporcionar las variables separadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9606 - loss: 0.2324 - val_accuracy: 0.6496 - val_loss: 0.8047\n",
      "Epoch 2/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0053 - val_accuracy: 0.6806 - val_loss: 0.7407\n",
      "Epoch 3/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0043 - val_accuracy: 0.6703 - val_loss: 0.8690\n",
      "Epoch 4/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0036 - val_accuracy: 0.6742 - val_loss: 0.8527\n",
      "Epoch 5/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0033 - val_accuracy: 0.6452 - val_loss: 1.1791\n",
      "Epoch 6/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0032 - val_accuracy: 0.6557 - val_loss: 1.0529\n",
      "Epoch 7/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0037 - val_accuracy: 0.6740 - val_loss: 1.0282\n",
      "Epoch 8/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.6612 - val_loss: 1.1855\n",
      "Epoch 9/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0020 - val_accuracy: 0.6512 - val_loss: 1.2304\n",
      "Epoch 10/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0027 - val_accuracy: 0.6742 - val_loss: 1.0659\n",
      "Epoch 11/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0020 - val_accuracy: 0.6797 - val_loss: 1.0786\n",
      "Epoch 12/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0018 - val_accuracy: 0.6329 - val_loss: 1.5234\n",
      "Epoch 13/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0029 - val_accuracy: 0.6785 - val_loss: 1.0975\n",
      "Epoch 14/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0021 - val_accuracy: 0.6721 - val_loss: 1.1445\n",
      "Epoch 15/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0011 - val_accuracy: 0.6587 - val_loss: 1.1629\n",
      "Epoch 16/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0014 - val_accuracy: 0.6769 - val_loss: 1.1115\n",
      "Epoch 17/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 9.5819e-04 - val_accuracy: 0.6630 - val_loss: 1.1708\n",
      "Epoch 18/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0018 - val_accuracy: 0.6762 - val_loss: 1.1548\n",
      "Epoch 19/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0017 - val_accuracy: 0.6769 - val_loss: 1.1689\n",
      "Epoch 20/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0023 - val_accuracy: 0.6500 - val_loss: 1.3825\n",
      "Epoch 21/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 9.8216e-04 - val_accuracy: 0.6493 - val_loss: 1.3419\n",
      "Epoch 22/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.6548 - val_loss: 1.2215\n",
      "Epoch 23/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0014 - val_accuracy: 0.6639 - val_loss: 1.2319\n",
      "Epoch 24/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0015 - val_accuracy: 0.6537 - val_loss: 1.2668\n",
      "Epoch 25/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0012 - val_accuracy: 0.6548 - val_loss: 1.3140\n",
      "Epoch 26/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0013 - val_accuracy: 0.6413 - val_loss: 1.4686\n",
      "Epoch 27/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0016 - val_accuracy: 0.6461 - val_loss: 1.3533\n",
      "Epoch 28/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0013 - val_accuracy: 0.6632 - val_loss: 1.2984\n",
      "Epoch 29/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0012 - val_accuracy: 0.6484 - val_loss: 1.4392\n",
      "Epoch 30/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0013 - val_accuracy: 0.6496 - val_loss: 1.4751\n",
      "Epoch 31/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 9.6738e-04 - val_accuracy: 0.6518 - val_loss: 1.4921\n",
      "Epoch 32/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 7.8616e-04 - val_accuracy: 0.6553 - val_loss: 1.4963\n",
      "Epoch 33/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 7.8016e-04 - val_accuracy: 0.6527 - val_loss: 1.5463\n",
      "Epoch 34/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0011 - val_accuracy: 0.6543 - val_loss: 1.5551\n",
      "Epoch 35/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 9.3564e-04 - val_accuracy: 0.6516 - val_loss: 1.6181\n",
      "Epoch 36/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0016 - val_accuracy: 0.6493 - val_loss: 1.6740\n",
      "Epoch 37/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 5.9535e-04 - val_accuracy: 0.6473 - val_loss: 1.7098\n",
      "Epoch 38/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.6484 - val_loss: 1.7454\n",
      "Epoch 39/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 8.6433e-04 - val_accuracy: 0.6489 - val_loss: 1.7494\n",
      "Epoch 40/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0010 - val_accuracy: 0.6491 - val_loss: 1.7585\n",
      "Epoch 41/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0013 - val_accuracy: 0.6502 - val_loss: 1.7791\n",
      "Epoch 42/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 6.1138e-04 - val_accuracy: 0.6500 - val_loss: 1.7910\n",
      "Epoch 43/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 7.6431e-04 - val_accuracy: 0.6505 - val_loss: 1.8025\n",
      "Epoch 44/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0015 - val_accuracy: 0.6454 - val_loss: 1.8677\n",
      "Epoch 45/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 5.3053e-04 - val_accuracy: 0.6587 - val_loss: 1.5947\n",
      "Epoch 46/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0012 - val_accuracy: 0.6532 - val_loss: 1.6825\n",
      "Epoch 47/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0013 - val_accuracy: 0.6516 - val_loss: 1.7799\n",
      "Epoch 48/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 4.8311e-04 - val_accuracy: 0.6482 - val_loss: 1.8463\n",
      "Epoch 49/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0014 - val_accuracy: 0.6571 - val_loss: 1.6852\n",
      "Epoch 50/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 7.3693e-04 - val_accuracy: 0.6530 - val_loss: 1.7548\n",
      "Epoch 51/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.6509 - val_loss: 1.7912\n",
      "Epoch 52/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 9.8637e-04 - val_accuracy: 0.6555 - val_loss: 1.8104\n",
      "Epoch 53/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 8.9118e-04 - val_accuracy: 0.6518 - val_loss: 1.8496\n",
      "Epoch 54/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 9.6269e-04 - val_accuracy: 0.6557 - val_loss: 1.8757\n",
      "Epoch 55/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 7.7612e-04 - val_accuracy: 0.6525 - val_loss: 1.9270\n",
      "Epoch 56/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0013 - val_accuracy: 0.6537 - val_loss: 1.9438\n",
      "Epoch 57/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0012 - val_accuracy: 0.6591 - val_loss: 1.9490\n",
      "Epoch 58/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0012 - val_accuracy: 0.6498 - val_loss: 1.9919\n",
      "Epoch 59/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.6496 - val_loss: 2.0332\n",
      "Epoch 60/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.6496 - val_loss: 2.0524\n",
      "Epoch 61/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 0.6434 - val_loss: 2.1499\n",
      "Epoch 62/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0010 - val_accuracy: 0.6480 - val_loss: 2.0528\n",
      "Epoch 63/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 9.1298e-04 - val_accuracy: 0.6491 - val_loss: 2.0909\n",
      "Epoch 64/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 9.7474e-04 - val_accuracy: 0.6491 - val_loss: 2.1383\n",
      "Epoch 65/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0016 - val_accuracy: 0.6541 - val_loss: 2.1180\n",
      "Epoch 66/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 7.3520e-04 - val_accuracy: 0.6500 - val_loss: 2.1519\n",
      "Epoch 67/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0010 - val_accuracy: 0.6491 - val_loss: 2.1366\n",
      "Epoch 68/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 7.0617e-04 - val_accuracy: 0.6439 - val_loss: 2.2015\n",
      "Epoch 69/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 8.6395e-04 - val_accuracy: 0.6550 - val_loss: 1.8770\n",
      "Epoch 70/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 8.6454e-04 - val_accuracy: 0.6527 - val_loss: 1.9568\n",
      "Epoch 71/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0013 - val_accuracy: 0.6516 - val_loss: 2.0219\n",
      "Epoch 72/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 4.9323e-04 - val_accuracy: 0.6523 - val_loss: 2.0858\n",
      "Epoch 73/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 9.7965e-04 - val_accuracy: 0.6537 - val_loss: 2.0760\n",
      "Epoch 74/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 7.0188e-04 - val_accuracy: 0.6509 - val_loss: 2.1035\n",
      "Epoch 75/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 9.0607e-04 - val_accuracy: 0.6491 - val_loss: 2.1592\n",
      "Epoch 76/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 9.0694e-04 - val_accuracy: 0.6605 - val_loss: 1.9329\n",
      "Epoch 77/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0011 - val_accuracy: 0.6464 - val_loss: 2.1073\n",
      "Epoch 78/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 9.8639e-04 - val_accuracy: 0.6532 - val_loss: 2.0716\n",
      "Epoch 79/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 9.6492e-04 - val_accuracy: 0.6687 - val_loss: 1.8886\n",
      "Epoch 80/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0012 - val_accuracy: 0.6619 - val_loss: 1.9800\n",
      "Epoch 81/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 7.6953e-04 - val_accuracy: 0.6596 - val_loss: 2.0218\n",
      "Epoch 82/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0011 - val_accuracy: 0.6589 - val_loss: 2.0490\n",
      "Epoch 83/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 9.1988e-04 - val_accuracy: 0.6416 - val_loss: 2.0669\n",
      "Epoch 84/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.6427 - val_loss: 2.0954\n",
      "Epoch 85/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0014 - val_accuracy: 0.6427 - val_loss: 2.1121\n",
      "Epoch 86/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 8.5840e-04 - val_accuracy: 0.6443 - val_loss: 2.1350\n",
      "Epoch 87/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 8.0333e-04 - val_accuracy: 0.6418 - val_loss: 2.1768\n",
      "Epoch 88/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0012 - val_accuracy: 0.6448 - val_loss: 2.1591\n",
      "Epoch 89/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 8.7544e-04 - val_accuracy: 0.6443 - val_loss: 2.1771\n",
      "Epoch 90/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0022 - val_accuracy: 0.6439 - val_loss: 2.1727\n",
      "Epoch 91/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0011 - val_accuracy: 0.6432 - val_loss: 2.2163\n",
      "Epoch 92/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0012 - val_accuracy: 0.6436 - val_loss: 2.1768\n",
      "Epoch 93/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 8.4736e-04 - val_accuracy: 0.6439 - val_loss: 2.2004\n",
      "Epoch 94/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0014 - val_accuracy: 0.6441 - val_loss: 2.1941\n",
      "Epoch 95/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 6.3700e-04 - val_accuracy: 0.6445 - val_loss: 2.2240\n",
      "Epoch 96/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 7.5642e-04 - val_accuracy: 0.6439 - val_loss: 2.2462\n",
      "Epoch 97/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0011 - val_accuracy: 0.6436 - val_loss: 2.2718\n",
      "Epoch 98/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0011 - val_accuracy: 0.6441 - val_loss: 2.2614\n",
      "Epoch 99/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0017 - val_accuracy: 0.6443 - val_loss: 2.2844\n",
      "Epoch 100/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 9.3008e-04 - val_accuracy: 0.6450 - val_loss: 2.3319\n",
      "Epoch 101/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0011 - val_accuracy: 0.6400 - val_loss: 2.3040\n",
      "Epoch 102/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0013 - val_accuracy: 0.6391 - val_loss: 2.3256\n",
      "Epoch 103/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0012 - val_accuracy: 0.6441 - val_loss: 2.2550\n",
      "Epoch 104/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 6.6324e-04 - val_accuracy: 0.6420 - val_loss: 2.3092\n",
      "Epoch 105/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 7.7663e-04 - val_accuracy: 0.6432 - val_loss: 2.3227\n",
      "Epoch 106/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0013 - val_accuracy: 0.6436 - val_loss: 2.3273\n",
      "Epoch 107/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0011 - val_accuracy: 0.6420 - val_loss: 2.3891\n",
      "Epoch 108/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0010 - val_accuracy: 0.6407 - val_loss: 2.4047\n",
      "Epoch 109/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 6.1903e-04 - val_accuracy: 0.6411 - val_loss: 2.4273\n",
      "Epoch 110/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 9.5550e-04 - val_accuracy: 0.6391 - val_loss: 2.4438\n",
      "Epoch 111/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 6.1039e-04 - val_accuracy: 0.6334 - val_loss: 2.7510\n",
      "Epoch 112/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0016 - val_accuracy: 0.6404 - val_loss: 2.2270\n",
      "Epoch 113/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0013 - val_accuracy: 0.6448 - val_loss: 2.2263\n",
      "Epoch 114/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 8.0712e-04 - val_accuracy: 0.6454 - val_loss: 2.2478\n",
      "Epoch 115/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 9.0273e-04 - val_accuracy: 0.6445 - val_loss: 2.2584\n",
      "Epoch 116/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 7.3564e-04 - val_accuracy: 0.6454 - val_loss: 2.2827\n",
      "Epoch 117/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0011 - val_accuracy: 0.6450 - val_loss: 2.2857\n",
      "Epoch 118/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 9.9951e-04 - val_accuracy: 0.6436 - val_loss: 2.3161\n",
      "Epoch 119/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 6.4282e-04 - val_accuracy: 0.6459 - val_loss: 2.3394\n",
      "Epoch 120/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 8.4826e-04 - val_accuracy: 0.6432 - val_loss: 2.3362\n",
      "Epoch 121/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0014 - val_accuracy: 0.6425 - val_loss: 2.3517\n",
      "Epoch 122/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0014 - val_accuracy: 0.6420 - val_loss: 2.3690\n",
      "Epoch 123/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 8.1429e-04 - val_accuracy: 0.6427 - val_loss: 2.3827\n",
      "Epoch 124/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 9.3480e-04 - val_accuracy: 0.6427 - val_loss: 2.3917\n",
      "Epoch 125/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 9.8528e-04 - val_accuracy: 0.6425 - val_loss: 2.4085\n",
      "Epoch 126/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0014 - val_accuracy: 0.6407 - val_loss: 2.4241\n",
      "Epoch 127/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0013 - val_accuracy: 0.6404 - val_loss: 2.4359\n",
      "Epoch 128/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0010 - val_accuracy: 0.6402 - val_loss: 2.4854\n",
      "Epoch 129/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 7.6518e-04 - val_accuracy: 0.6413 - val_loss: 2.4308\n",
      "Epoch 130/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 9.9266e-04 - val_accuracy: 0.6404 - val_loss: 2.4425\n",
      "Epoch 131/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0012 - val_accuracy: 0.6429 - val_loss: 2.4147\n",
      "Epoch 132/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 9.5499e-04 - val_accuracy: 0.6429 - val_loss: 2.4079\n",
      "Epoch 133/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 8.1288e-04 - val_accuracy: 0.6425 - val_loss: 2.4285\n",
      "Epoch 134/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 9.8929e-04 - val_accuracy: 0.6418 - val_loss: 2.4462\n",
      "Epoch 135/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0013 - val_accuracy: 0.6416 - val_loss: 2.4643\n",
      "Epoch 136/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 8.8830e-04 - val_accuracy: 0.6409 - val_loss: 2.4787\n",
      "Epoch 137/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 8.8188e-04 - val_accuracy: 0.6427 - val_loss: 2.4912\n",
      "Epoch 138/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 9.2652e-04 - val_accuracy: 0.6418 - val_loss: 2.4906\n",
      "Epoch 139/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0014 - val_accuracy: 0.6411 - val_loss: 2.5110\n",
      "Epoch 140/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0015 - val_accuracy: 0.6407 - val_loss: 2.4668\n",
      "Epoch 141/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 6.4430e-04 - val_accuracy: 0.6411 - val_loss: 2.5069\n",
      "Epoch 142/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 8.0428e-04 - val_accuracy: 0.6400 - val_loss: 2.5279\n",
      "Epoch 143/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 9.3751e-04 - val_accuracy: 0.6402 - val_loss: 2.5632\n",
      "Epoch 144/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 8.3275e-04 - val_accuracy: 0.6397 - val_loss: 2.5838\n",
      "Epoch 145/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0014 - val_accuracy: 0.6416 - val_loss: 2.4582\n",
      "Epoch 146/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 9.7194e-04 - val_accuracy: 0.6384 - val_loss: 2.5238\n",
      "Epoch 147/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0011 - val_accuracy: 0.6384 - val_loss: 2.5466\n",
      "Epoch 148/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0013 - val_accuracy: 0.6381 - val_loss: 2.5615\n",
      "Epoch 149/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 8.2014e-04 - val_accuracy: 0.6384 - val_loss: 2.5814\n",
      "Epoch 150/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0011 - val_accuracy: 0.6375 - val_loss: 2.6113\n",
      "Epoch 151/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.6370 - val_loss: 2.6021\n",
      "Epoch 152/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0013 - val_accuracy: 0.6368 - val_loss: 2.6598\n",
      "Epoch 153/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 8.3962e-04 - val_accuracy: 0.6361 - val_loss: 2.5150\n",
      "Epoch 154/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 5.0640e-04 - val_accuracy: 0.6370 - val_loss: 2.4815\n",
      "Epoch 155/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0013 - val_accuracy: 0.6375 - val_loss: 2.5069\n",
      "Epoch 156/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 8.9787e-04 - val_accuracy: 0.6370 - val_loss: 2.5347\n",
      "Epoch 157/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0014 - val_accuracy: 0.6372 - val_loss: 2.5409\n",
      "Epoch 158/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 6.0845e-04 - val_accuracy: 0.6375 - val_loss: 2.5590\n",
      "Epoch 159/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 8.9693e-04 - val_accuracy: 0.6375 - val_loss: 2.5702\n",
      "Epoch 160/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0014 - val_accuracy: 0.6379 - val_loss: 2.5696\n",
      "Epoch 161/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 9.1567e-04 - val_accuracy: 0.6377 - val_loss: 2.6388\n",
      "Epoch 162/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0011 - val_accuracy: 0.6377 - val_loss: 2.6174\n",
      "Epoch 163/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0011 - val_accuracy: 0.6377 - val_loss: 2.6111\n",
      "Epoch 164/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0011 - val_accuracy: 0.6377 - val_loss: 2.6262\n",
      "Epoch 165/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 9.3006e-04 - val_accuracy: 0.6370 - val_loss: 2.6363\n",
      "Epoch 166/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 8.9074e-04 - val_accuracy: 0.6375 - val_loss: 2.6434\n",
      "Epoch 167/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.6375 - val_loss: 2.6588\n",
      "Epoch 168/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 9.2585e-04 - val_accuracy: 0.6379 - val_loss: 2.6656\n",
      "Epoch 169/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 6.8930e-04 - val_accuracy: 0.6379 - val_loss: 2.6397\n",
      "Epoch 170/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0017 - val_accuracy: 0.6381 - val_loss: 2.6400\n",
      "Epoch 171/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0010 - val_accuracy: 0.6381 - val_loss: 2.6506\n",
      "Epoch 172/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 9.5854e-04 - val_accuracy: 0.6381 - val_loss: 2.6757\n",
      "Epoch 173/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0015 - val_accuracy: 0.6372 - val_loss: 2.6838\n",
      "Epoch 174/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 7.3571e-04 - val_accuracy: 0.6372 - val_loss: 2.7031\n",
      "Epoch 175/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 5.1406e-04 - val_accuracy: 0.6384 - val_loss: 2.6958\n",
      "Epoch 176/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 6.9306e-04 - val_accuracy: 0.6368 - val_loss: 2.7293\n",
      "Epoch 177/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0012 - val_accuracy: 0.6375 - val_loss: 2.7397\n",
      "Epoch 178/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 6.2487e-04 - val_accuracy: 0.6354 - val_loss: 2.7872\n",
      "Epoch 179/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0013 - val_accuracy: 0.6354 - val_loss: 2.7636\n",
      "Epoch 180/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0010 - val_accuracy: 0.6384 - val_loss: 2.8018\n",
      "Epoch 181/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 8.2801e-04 - val_accuracy: 0.6356 - val_loss: 2.8025\n",
      "Epoch 182/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 6.3350e-04 - val_accuracy: 0.6354 - val_loss: 2.8012\n",
      "Epoch 183/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 8.2483e-04 - val_accuracy: 0.6350 - val_loss: 2.7928\n",
      "Epoch 184/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0015 - val_accuracy: 0.6366 - val_loss: 2.7898\n",
      "Epoch 185/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 9.8307e-04 - val_accuracy: 0.6366 - val_loss: 2.7776\n",
      "Epoch 186/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 7.5944e-04 - val_accuracy: 0.6359 - val_loss: 2.8039\n",
      "Epoch 187/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0014 - val_accuracy: 0.6363 - val_loss: 2.8233\n",
      "Epoch 188/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 6.4219e-04 - val_accuracy: 0.6366 - val_loss: 2.8599\n",
      "Epoch 189/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0010 - val_accuracy: 0.6366 - val_loss: 2.8329\n",
      "Epoch 190/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 9.4565e-04 - val_accuracy: 0.6340 - val_loss: 2.9323\n",
      "Epoch 191/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 8.5083e-04 - val_accuracy: 0.6368 - val_loss: 2.8781\n",
      "Epoch 192/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 9.6919e-04 - val_accuracy: 0.6356 - val_loss: 2.9286\n",
      "Epoch 193/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 9.5372e-04 - val_accuracy: 0.6541 - val_loss: 2.4823\n",
      "Epoch 194/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 9.8522e-04 - val_accuracy: 0.6514 - val_loss: 2.5244\n",
      "Epoch 195/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 6.9530e-04 - val_accuracy: 0.6521 - val_loss: 2.5662\n",
      "Epoch 196/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0012 - val_accuracy: 0.6491 - val_loss: 2.6048\n",
      "Epoch 197/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0010 - val_accuracy: 0.6484 - val_loss: 2.6314\n",
      "Epoch 198/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0014 - val_accuracy: 0.6486 - val_loss: 2.6487\n",
      "Epoch 199/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.6473 - val_loss: 2.6792\n",
      "Epoch 200/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 7.1493e-04 - val_accuracy: 0.6475 - val_loss: 2.6975\n",
      "Epoch 201/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0017 - val_accuracy: 0.6452 - val_loss: 2.7159\n",
      "Epoch 202/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 8.9361e-04 - val_accuracy: 0.6461 - val_loss: 2.7229\n",
      "Epoch 203/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 8.9095e-04 - val_accuracy: 0.6466 - val_loss: 2.7318\n",
      "Epoch 204/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 9.4120e-04 - val_accuracy: 0.6459 - val_loss: 2.7474\n",
      "Epoch 205/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 9.5011e-04 - val_accuracy: 0.6452 - val_loss: 2.7687\n",
      "Epoch 206/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 9.4286e-04 - val_accuracy: 0.6452 - val_loss: 2.7956\n",
      "Epoch 207/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 9.4309e-04 - val_accuracy: 0.6454 - val_loss: 2.7999\n",
      "Epoch 208/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 8.8315e-04 - val_accuracy: 0.6459 - val_loss: 2.8109\n",
      "Epoch 209/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0011 - val_accuracy: 0.6454 - val_loss: 2.8361\n",
      "Epoch 210/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 7.7230e-04 - val_accuracy: 0.6452 - val_loss: 2.8275\n",
      "Epoch 211/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 7.8117e-04 - val_accuracy: 0.6452 - val_loss: 2.8388\n",
      "Epoch 212/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0011 - val_accuracy: 0.6443 - val_loss: 2.8635\n",
      "Epoch 213/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0018 - val_accuracy: 0.6439 - val_loss: 2.8639\n",
      "Epoch 214/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 8.0827e-04 - val_accuracy: 0.6445 - val_loss: 2.8514\n",
      "Epoch 215/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0013 - val_accuracy: 0.6445 - val_loss: 2.8702\n",
      "Epoch 216/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 5.4682e-04 - val_accuracy: 0.6450 - val_loss: 2.8810\n",
      "Epoch 217/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0012 - val_accuracy: 0.6434 - val_loss: 2.9111\n",
      "Epoch 218/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.6423 - val_loss: 2.8964\n",
      "Epoch 219/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 9.6621e-04 - val_accuracy: 0.6445 - val_loss: 2.8769\n",
      "Epoch 220/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0011 - val_accuracy: 0.6439 - val_loss: 2.8880\n",
      "Epoch 221/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0011 - val_accuracy: 0.6439 - val_loss: 2.9016\n",
      "Epoch 222/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 9.0374e-04 - val_accuracy: 0.6434 - val_loss: 2.9205\n",
      "Epoch 223/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 6.9160e-04 - val_accuracy: 0.6423 - val_loss: 2.9577\n",
      "Epoch 224/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 7.8734e-04 - val_accuracy: 0.6439 - val_loss: 2.9416\n",
      "Epoch 225/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.6425 - val_loss: 2.9537\n",
      "Epoch 226/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.6425 - val_loss: 2.9438\n",
      "Epoch 227/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 7.3186e-04 - val_accuracy: 0.6530 - val_loss: 2.6584\n",
      "Epoch 228/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0014 - val_accuracy: 0.6445 - val_loss: 3.1923\n",
      "Epoch 229/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0018 - val_accuracy: 0.6368 - val_loss: 1.9744\n",
      "Epoch 230/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0015 - val_accuracy: 0.6589 - val_loss: 1.6713\n",
      "Epoch 231/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 6.9838e-04 - val_accuracy: 0.6585 - val_loss: 1.6813\n",
      "Epoch 232/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 7.2441e-04 - val_accuracy: 0.6573 - val_loss: 1.6893\n",
      "Epoch 233/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0014 - val_accuracy: 0.6575 - val_loss: 1.6910\n",
      "Epoch 234/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.6589 - val_loss: 1.6954\n",
      "Epoch 235/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 8.9450e-04 - val_accuracy: 0.6573 - val_loss: 1.7084\n",
      "Epoch 236/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 9.1481e-04 - val_accuracy: 0.6569 - val_loss: 1.7088\n",
      "Epoch 237/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 6.6646e-04 - val_accuracy: 0.6578 - val_loss: 1.7221\n",
      "Epoch 238/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0011 - val_accuracy: 0.6582 - val_loss: 1.7335\n",
      "Epoch 239/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 5.9591e-04 - val_accuracy: 0.6573 - val_loss: 1.7419\n",
      "Epoch 240/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 8.1950e-04 - val_accuracy: 0.6580 - val_loss: 1.7564\n",
      "Epoch 241/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0012 - val_accuracy: 0.6580 - val_loss: 1.7622\n",
      "Epoch 242/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0014 - val_accuracy: 0.6571 - val_loss: 1.7733\n",
      "Epoch 243/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 8.2882e-04 - val_accuracy: 0.6575 - val_loss: 1.7787\n",
      "Epoch 244/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 6.5228e-04 - val_accuracy: 0.6580 - val_loss: 1.7886\n",
      "Epoch 245/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0016 - val_accuracy: 0.6575 - val_loss: 1.8025\n",
      "Epoch 246/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 8.5339e-04 - val_accuracy: 0.6571 - val_loss: 1.8225\n",
      "Epoch 247/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 8.7373e-04 - val_accuracy: 0.6564 - val_loss: 1.8386\n",
      "Epoch 248/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0014 - val_accuracy: 0.6559 - val_loss: 1.8571\n",
      "Epoch 249/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0013 - val_accuracy: 0.6557 - val_loss: 1.8723\n",
      "Epoch 250/250\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 8.3694e-04 - val_accuracy: 0.6557 - val_loss: 1.8853\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    [X_train_denom, X_train_opo, X_train_class],  # Entradas\n",
    "    y_train,  # Variable objetivo\n",
    "    validation_data=([X_test_denom, X_test_opo, X_test_class], y_test), # Datos de validación\n",
    "    epochs=250,  # Número de épocas\n",
    "    batch_size=32  # Tamaño de lote\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último pasamos a la evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.6571 - loss: 1.8193\n",
      "Test Accuracy: 0.65571528673172\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de test\n",
    "loss, accuracy = model.evaluate([X_test_denom, X_test_opo, X_test_class], y_test)\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
